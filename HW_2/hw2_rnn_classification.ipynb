{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1acf78a",
   "metadata": {
    "id": "b1acf78a"
   },
   "source": [
    "# Глубинное обучение для текстовых данных, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 2: Рекуррентные нейронные сети\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — __10 (+3) баллов__. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Весь код должен быть написан самостоятельно. Чужим кодом для пользоваться запрещается даже с указанием ссылки на источник. В разумных рамках, конечно. Взять пару очевидных строчек кода для реализации какого-то небольшого функционала можно.\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "__Мягкий дедлайн: 5.10.25 23:59__   \n",
    "__Жесткий дедлайн: 8.10.25 23:59__\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит самостоятельно реализовать модель LSTM для решения задачи классификации с пересекающимися классами (multi-label classification). Это вид классификации, в которой каждый объект может относиться одновременно к нескольким классам. Такая задача часто возникает при классификации фильмов по жанрам, научных или новостных статей по темам, музыкальных композиций по инструментам и так далее.\n",
    "\n",
    "В нашем случае мы будем работать с датасетом биотехнических новостей и классифицировать их по темам. Этот датасет уже предобработан: текст приведен к нижнему регистру, удалена пунктуация, все слова разделены проблелом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1a5fff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "af1a5fff",
    "outputId": "891c58cd-6964-4319-ade3-92bb90356f93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive your plow over the bones of the dead by ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the recently tabled national budget denel h...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shares take a break its good for you picture g...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reso is currently hiring for two positions pro...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charter buyer club what is the charter buyer c...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0  drive your plow over the bones of the dead by ...  other\n",
       "1  in the recently tabled national budget denel h...  other\n",
       "2  shares take a break its good for you picture g...  other\n",
       "3  reso is currently hiring for two positions pro...  other\n",
       "4  charter buyer club what is the charter buyer c...  other"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('biotech_news.tsv', sep='\\t')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e07549e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3039"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HRBZwYd9QMMS",
   "metadata": {
    "id": "HRBZwYd9QMMS"
   },
   "source": [
    "## Предобработка лейблов\n",
    "\n",
    "\n",
    "__Задание 1 (0.5 балла)__. Как вы можете заметить, лейблы записаны в виде строк, разделенных запятыми. Для работы с ними нам нужно преобразовать их в числа. Так как каждый объект может принадлежать нескольким классам, закодируйте лейблы в виде векторов из 0 и 1, где 1 означает, что объект принадлежит соответствующему классу, а 0 – не принадлежит. Имея такую кодировку, мы сможем обучить модель, решая задачу бинарной классификации для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c65a9bf-dbe9-4cad-978d-3a0e10b1eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y = mlb.fit_transform(dataset['labels'].str.split(', '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0296f-9699-475e-b4bd-c9e531dca2d4",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vMe0c5AAXM8d",
   "metadata": {
    "id": "vMe0c5AAXM8d"
   },
   "source": [
    "В этом задании мы будем обучать рекуррентные нейронные сети. Как вы знаете, они работают лучше для коротких текстов, так как не очень хорошо улавливают далекие зависимости. Для уменьшение длин текстов их стоит почистить.\n",
    "\n",
    "Сразу разделим выборку на обучающую и тестовую, чтобы считать все нужные статистики только по обучающей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8135000",
   "metadata": {
    "id": "f8135000"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(\n",
    "    dataset['text'],\n",
    "    y,\n",
    "    test_size=0.2,  # do not change this\n",
    "    random_state=0  # do not change this\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace679c-db5f-45d3-8fa3-6a5c55eb912a",
   "metadata": {},
   "source": [
    "__Задание 2 (1 балл)__. Удалите из текстов стоп слова, слишком редкие и слишком частые слова. Гиперпараметры подберите самостоятельно (в идеале их стоит подбирать по качеству на тестовой выборке). Если вы считаете, что стоит добавить еще какую-то обработку, то сделайте это. Важно не удалить ничего, что может повлиять на предсказание класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01fa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192dfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486ff2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f4848c2-7fe1-43f9-8564-1144015fc29b",
   "metadata": {},
   "source": [
    "__Задание 3 (1.5 балла)__. Осталось перевести тексты в индексы токенов, чтобы их можно было подавать в модель. У вас есть две опции, как это сделать:\n",
    "1. __(+0 баллов)__ Токенизировать тексты по словам.\n",
    "2. __(до +3 баллов)__ Реализовать свою токенизацию BPE. Количество баллов будет варьироваться в зависимости от эффективности реализации. При реализации нельзя пользоваться специализированными библиотеками.\n",
    "\n",
    "Токенизируйте тексты, переведите их в списки индексов и сложите вместе с лейблами в `DataLoader`. Не забудьте добавить в `DataLoader` `collate_fn`, которая будет дополнять все короткие тексты в батче паддингами. Для маппинга токенов в индексы вам может пригодиться `gensim.corpora.dictionary.Dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de181ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 21163, PAD_ID=21159, UNK_ID=21160, BOS_ID=21161, EOS_ID=21162\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import Counter\n",
    "from gensim.corpora import Dictionary\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from functools import partial\n",
    "\n",
    "# --- Предобработка ---\n",
    "STOP_WORDS = list(set(ENGLISH_STOP_WORDS) - {\"no\", \"not\"})\n",
    "\n",
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)  # только латиница и пробелы\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in STOP_WORDS]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "train_tokens = [process_text(t) for t in texts_train]\n",
    "test_tokens  = [process_text(t) for t in texts_test]\n",
    "\n",
    "\n",
    "df = Counter()\n",
    "for doc in train_tokens:\n",
    "    df.update(set(doc))  \n",
    "\n",
    "min_df = 2\n",
    "max_df_fraction = 0.9\n",
    "max_df_count = int(max_df_fraction * len(train_tokens))\n",
    "\n",
    "valid_words = {w for w, c in df.items() if min_df <= c <= max_df_count}\n",
    "\n",
    "def filter_tokens(tokens):\n",
    "    return [t for t in tokens if t in valid_words]\n",
    "\n",
    "train_tokens_filtered = [filter_tokens(doc) for doc in train_tokens]\n",
    "test_tokens_filtered  = [filter_tokens(doc) for doc in test_tokens]\n",
    "\n",
    "\n",
    "vocab = Dictionary(train_tokens_filtered)\n",
    "\n",
    "\n",
    "special_tokens = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]\n",
    "for token in special_tokens:\n",
    "    if token not in vocab.token2id:\n",
    "        vocab.token2id[token] = len(vocab)\n",
    "PAD_ID = vocab.token2id[\"<pad>\"]\n",
    "UNK_ID = vocab.token2id[\"<unk>\"]\n",
    "BOS_ID = vocab.token2id[\"<bos>\"]\n",
    "EOS_ID = vocab.token2id[\"<eos>\"]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# --- Кодировщик с BOS/EOS и max_length ---\n",
    "def encode(tokens, max_length=None):\n",
    "    if not tokens:\n",
    "        return [UNK_ID]\n",
    "\n",
    "    ids = [BOS_ID] + [vocab.token2id.get(t, UNK_ID) for t in tokens] + [EOS_ID]\n",
    "\n",
    "    if max_length:\n",
    "        if len(ids) > max_length:\n",
    "            ids = ids[:max_length - 1] + [EOS_ID] \n",
    "    return ids\n",
    "\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "X_train = [encode(t, max_length=MAX_LENGTH) for t in train_tokens_filtered]\n",
    "X_test  = [encode(t, max_length=MAX_LENGTH) for t in test_tokens_filtered]\n",
    "\n",
    "# --- Dataset / DataLoader ---\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.seq = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = torch.tensor(self.seq[i], dtype=torch.long)\n",
    "        y = torch.tensor(self.labels[i], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch, pad_id):\n",
    "    seqs, labels = zip(*batch)\n",
    "    seqs = [torch.tensor(s, dtype=torch.long) for s in seqs]\n",
    "\n",
    "    padded = pad_sequence(seqs, batch_first=True, padding_value=pad_id)\n",
    "    labels = torch.stack(labels)\n",
    "    return padded, labels\n",
    "\n",
    "collate = partial(collate_fn, pad_id=PAD_ID)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TextDataset(X_train, y_train), batch_size=batch_size,\n",
    "                          shuffle=True, collate_fn=collate)\n",
    "test_loader  = DataLoader(TextDataset(X_test,  y_test),  batch_size=batch_size,\n",
    "                          shuffle=False, collate_fn=collate)\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}, PAD_ID={PAD_ID}, UNK_ID={UNK_ID}, BOS_ID={BOS_ID}, EOS_ID={EOS_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e78f9-6bef-46f4-8b58-818b7eb0c082",
   "metadata": {},
   "source": [
    "## Метрика качества\n",
    "\n",
    "Перед тем, как приступить к обучению, нам нужно выбрать метрику оценки качества. Так как в задаче классификации с пересекающимися классами классы часто несбалансированы, чаще всего в качестве метрики берется [F1 score](https://en.wikipedia.org/wiki/F-score).\n",
    "\n",
    "Функция `compute_f1` принимает истинные метки и предсказанные и считает среднее значение F1 по всем классам. Используйте ее для оценки качества моделей.\n",
    "\n",
    "$$\n",
    "F1_{total} = \\frac{1}{K} \\sum_{k=1}^K F1(Y_k, \\hat{Y}_k),\n",
    "$$\n",
    "где $Y_k$ – истинные значения для класса k, а $\\hat{Y}_k$ – предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "671a0928-fd68-4f36-bae7-2dacb18fd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_f1(y_true, y_pred):\n",
    "    assert y_true.ndim == 2\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aagj29J7Ap2H",
   "metadata": {
    "id": "aagj29J7Ap2H"
   },
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae5666",
   "metadata": {
    "id": "56ae5666"
   },
   "source": [
    "### RNN\n",
    "\n",
    "В качестве бейзлайна обучим самую простую рекуррентную нейронную сеть. Напомним, что блок RNN выглядит таким образом.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/yYbNBm6G/tg-image-1635618906.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Его скрытое состояние обновляется по формуле\n",
    "$h_t = \\sigma(W x_{t} + U h_{t-1} + b_h)$. А предсказание считается с помощью применения линейного слоя к последнему токену\n",
    "$o_T = V h_T + b_o$. В качестве функции активации выберите гиперболический тангенс. \n",
    "\n",
    "__Задание 4 (2 балла)__. Реализуйте RNN в соответствии с формулой выше и обучите ее на нашу задачу. Нулевой скрытый вектор инициализируйте нулями, так модель будет обучаться стабильнее, чем при случайной инициализации. После этого замеряйте качество на тестовой выборке. У вас должно получиться значение F1 не меньше 0.33, а само обучение не должно занимать много времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05743f95-dd39-43f5-81cf-1a79edc194fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_labels):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        self.input_linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.hidden_linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.bias_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        x_emb = self.embedding(input_ids) \n",
    "\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size, device=x_emb.device)\n",
    "\n",
    "\n",
    "        for x_t in x_emb.transpose(0, 1): \n",
    "            h_t = torch.tanh(self.input_linear(x_t) + self.hidden_linear(h_t) + self.bias_h)\n",
    "\n",
    "\n",
    "        logits = self.output_layer(h_t)\n",
    "        return logits, h_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c15083d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 0.2166 | test F1 0.0240\n",
      "epoch 02 | train loss 0.1797 | test F1 0.0090\n",
      "epoch 03 | train loss 0.1766 | test F1 0.0264\n",
      "epoch 04 | train loss 0.1661 | test F1 0.0424\n",
      "epoch 05 | train loss 0.1478 | test F1 0.0470\n",
      "epoch 06 | train loss 0.1262 | test F1 0.0550\n",
      "epoch 07 | train loss 0.1054 | test F1 0.0695\n",
      "epoch 08 | train loss 0.0877 | test F1 0.0980\n",
      "epoch 09 | train loss 0.0719 | test F1 0.1351\n",
      "epoch 10 | train loss 0.0590 | test F1 0.1656\n",
      "epoch 11 | train loss 0.0485 | test F1 0.1895\n",
      "epoch 12 | train loss 0.0402 | test F1 0.2192\n",
      "epoch 13 | train loss 0.0339 | test F1 0.2533\n",
      "epoch 14 | train loss 0.0286 | test F1 0.2571\n",
      "epoch 15 | train loss 0.0242 | test F1 0.2752\n",
      "epoch 16 | train loss 0.0214 | test F1 0.3229\n",
      "epoch 17 | train loss 0.0192 | test F1 0.3087\n",
      "epoch 18 | train loss 0.0173 | test F1 0.3301\n",
      "epoch 19 | train loss 0.0158 | test F1 0.3271\n",
      "epoch 20 | train loss 0.0145 | test F1 0.3217\n",
      "epoch 21 | train loss 0.0134 | test F1 0.3321\n",
      "epoch 22 | train loss 0.0126 | test F1 0.3458\n",
      "epoch 23 | train loss 0.0120 | test F1 0.3380\n",
      "epoch 24 | train loss 0.0117 | test F1 0.3437\n",
      "epoch 25 | train loss 0.0111 | test F1 0.3458\n",
      "epoch 26 | train loss 0.0109 | test F1 0.3406\n",
      "epoch 27 | train loss 0.0106 | test F1 0.3487\n",
      "epoch 28 | train loss 0.0103 | test F1 0.3397\n",
      "epoch 29 | train loss 0.0101 | test F1 0.3433\n",
      "epoch 30 | train loss 0.0100 | test F1 0.3379\n",
      "epoch 31 | train loss 0.0098 | test F1 0.3348\n",
      "epoch 32 | train loss 0.0095 | test F1 0.3417\n",
      "epoch 33 | train loss 0.0093 | test F1 0.3348\n",
      "epoch 34 | train loss 0.0094 | test F1 0.3414\n",
      "epoch 35 | train loss 0.0092 | test F1 0.3305\n",
      "epoch 36 | train loss 0.0091 | test F1 0.3390\n",
      "epoch 37 | train loss 0.0090 | test F1 0.3376\n",
      "epoch 38 | train loss 0.0088 | test F1 0.3470\n",
      "epoch 39 | train loss 0.0087 | test F1 0.3452\n",
      "epoch 40 | train loss 0.0086 | test F1 0.3387\n",
      "epoch 41 | train loss 0.0085 | test F1 0.3434\n",
      "epoch 42 | train loss 0.0089 | test F1 0.3369\n",
      "epoch 43 | train loss 0.0090 | test F1 0.3487\n",
      "epoch 44 | train loss 0.0091 | test F1 0.3504\n",
      "epoch 45 | train loss 0.0087 | test F1 0.3390\n",
      "epoch 46 | train loss 0.0090 | test F1 0.3308\n",
      "epoch 47 | train loss 0.0094 | test F1 0.3302\n",
      "epoch 48 | train loss 0.0128 | test F1 0.3068\n",
      "epoch 49 | train loss 0.0651 | test F1 0.2014\n",
      "epoch 50 | train loss 0.0604 | test F1 0.2559\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_size = 256\n",
    "num_labels = y_train.shape[1]\n",
    "\n",
    "model = RNN(vocab_size, hidden_size, num_labels).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).int().cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y.cpu().int())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    return compute_f1(y_true, y_pred)\n",
    "\n",
    "num_epochs = 50\n",
    "f1_scores = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    test_f1 = evaluate(model, test_loader)\n",
    "    f1_scores.append(test_f1)\n",
    "    print(f\"epoch {epoch:02d} | train loss {total_loss/len(train_loader):.4f} | test F1 {test_f1:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5556509"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b590ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35040835298100204"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xqt0dk6LEJUU",
   "metadata": {
    "id": "xqt0dk6LEJUU"
   },
   "source": [
    "### LSTM\n",
    "\n",
    "<img src=\"https://i.postimg.cc/pL5LdmpL/tg-image-2290675322.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Теперь перейдем к более продвинутым рекурренным моделям, а именно LSTM. Из-за дополнительного вектора памяти эта модель должна гораздо лучше улавливать далекие зависимости, что должно напрямую отражаться на качестве.\n",
    "\n",
    "Параметры блока LSTM обновляются вот так ($\\sigma$ означает сигмоиду):\n",
    "\\begin{align}\n",
    "f_{t} &= \\sigma(W_f x_{t} + U_f h_{t-1} + b_f) \\\\ \n",
    "i_{t} &= \\sigma(W_i x_{t} + U_i h_{t-1} + b_i) \\\\\n",
    "\\tilde{c}_{t} &= \\tanh(W_c x_{t} + U_c h_{t-1} + b_i) \\\\\n",
    "c_{t} &= f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t \\\\\n",
    "o_{t} &= \\sigma(W_t x_{t} + U_t h_{t-1} + b_t) \\\\\n",
    "h_t &= o_t \\odot \\tanh(c_t)\n",
    "\\end{align}\n",
    "\n",
    "__Задание 5 (2 балла).__ Реализуйте LSTM по описанной схеме. Выберите гиперпараметры LSTM так, чтобы их общее число (без учета слоя эмбеддингов) примерно совпадало с числом параметров обычной RNN, но размерность скрытого слоя была не меньше 64. Так мы будем сравнивать архитектуры максимально независимо. Обучите LSTM до сходимости и сравните качество с RNN на тестовой выборке. Удалось ли получить лучший результат? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e18b79b-f2c6-4474-a5c0-c8ce51f13afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # Все веса: W_* (для x_t) и U_* (для h_{t-1})\n",
    "        self.W_f = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.U_f = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "\n",
    "        self.W_i = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.U_i = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "\n",
    "        self.W_c = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.U_c = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "\n",
    "        self.W_o = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.U_o = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, emb_dim)\n",
    "        batch_size, seq_len, _ = embedded.shape\n",
    "\n",
    "        h_t = torch.zeros(batch_size, self.U_f.out_features, device=x.device)\n",
    "        c_t = torch.zeros_like(h_t)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = embedded[:, t, :]\n",
    "\n",
    "            f_t = torch.sigmoid(self.W_f(x_t) + self.U_f(h_t))\n",
    "            i_t = torch.sigmoid(self.W_i(x_t) + self.U_i(h_t))\n",
    "            g_t = torch.tanh(self.W_c(x_t) + self.U_c(h_t))\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            o_t = torch.sigmoid(self.W_o(x_t) + self.U_o(h_t))\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        logits = self.fc(h_t)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ddfc5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 0.2365 | test F1 0.0240\n",
      "epoch 02 | train loss 0.1800 | test F1 0.0240\n",
      "epoch 03 | train loss 0.1802 | test F1 0.0346\n",
      "epoch 04 | train loss 0.1800 | test F1 0.0240\n",
      "epoch 05 | train loss 0.1798 | test F1 0.0240\n",
      "epoch 06 | train loss 0.1799 | test F1 0.0346\n",
      "epoch 07 | train loss 0.1801 | test F1 0.0240\n",
      "epoch 08 | train loss 0.1800 | test F1 0.0084\n",
      "epoch 09 | train loss 0.1803 | test F1 0.0091\n",
      "epoch 10 | train loss 0.1798 | test F1 0.0240\n",
      "epoch 11 | train loss 0.1798 | test F1 0.0240\n",
      "epoch 12 | train loss 0.1797 | test F1 0.0106\n",
      "epoch 13 | train loss 0.1798 | test F1 0.0240\n",
      "epoch 14 | train loss 0.1799 | test F1 0.0240\n",
      "epoch 15 | train loss 0.1774 | test F1 0.0204\n",
      "epoch 16 | train loss 0.1715 | test F1 0.0212\n",
      "epoch 17 | train loss 0.1643 | test F1 0.0224\n",
      "epoch 18 | train loss 0.1595 | test F1 0.0230\n",
      "epoch 19 | train loss 0.1552 | test F1 0.0396\n",
      "epoch 20 | train loss 0.1521 | test F1 0.0421\n",
      "epoch 21 | train loss 0.1484 | test F1 0.0454\n",
      "epoch 22 | train loss 0.1447 | test F1 0.0429\n",
      "epoch 23 | train loss 0.1399 | test F1 0.0476\n",
      "epoch 24 | train loss 0.1345 | test F1 0.0450\n",
      "epoch 25 | train loss 0.1294 | test F1 0.0530\n",
      "epoch 26 | train loss 0.1249 | test F1 0.0578\n",
      "epoch 27 | train loss 0.1202 | test F1 0.0547\n",
      "epoch 28 | train loss 0.1143 | test F1 0.0609\n",
      "epoch 29 | train loss 0.1088 | test F1 0.0608\n",
      "epoch 30 | train loss 0.1034 | test F1 0.0659\n",
      "epoch 31 | train loss 0.0973 | test F1 0.0728\n",
      "epoch 32 | train loss 0.0910 | test F1 0.0762\n",
      "epoch 33 | train loss 0.0843 | test F1 0.0864\n",
      "epoch 34 | train loss 0.0775 | test F1 0.0993\n",
      "epoch 35 | train loss 0.0708 | test F1 0.1164\n",
      "epoch 36 | train loss 0.0629 | test F1 0.1480\n",
      "epoch 37 | train loss 0.0547 | test F1 0.1694\n",
      "epoch 38 | train loss 0.0474 | test F1 0.1961\n",
      "epoch 39 | train loss 0.0416 | test F1 0.2090\n",
      "epoch 40 | train loss 0.0355 | test F1 0.2277\n",
      "epoch 41 | train loss 0.0296 | test F1 0.2886\n",
      "epoch 42 | train loss 0.0252 | test F1 0.2641\n",
      "epoch 43 | train loss 0.0216 | test F1 0.3294\n",
      "epoch 44 | train loss 0.0191 | test F1 0.3429\n",
      "epoch 45 | train loss 0.0165 | test F1 0.3538\n",
      "epoch 46 | train loss 0.0145 | test F1 0.3461\n",
      "epoch 47 | train loss 0.0127 | test F1 0.3462\n",
      "epoch 48 | train loss 0.0120 | test F1 0.3575\n",
      "epoch 49 | train loss 0.0106 | test F1 0.3697\n",
      "epoch 50 | train loss 0.0099 | test F1 0.3660\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_labels = y_train.shape[1]\n",
    "\n",
    "model = MyLSTM(vocab_size, embedding_dim=256, hidden_dim=256,\n",
    "               output_dim=y_train.shape[1], pad_idx=PAD_ID).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).int().cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y.cpu().int())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    return compute_f1(y_true, y_pred)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    test_f1 = evaluate(model, test_loader)\n",
    "    f1_scores.append(test_f1)\n",
    "    print(f\"epoch {epoch:02d} | train loss {total_loss/len(train_loader):.4f} | test F1 {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b87a2c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5951517"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c83be1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36965653399950305"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd186c",
   "metadata": {},
   "source": [
    "Обучение шло дольше, но зато за тоже количество эпох и параметров удалось получить лучше результат (~ на 0.02). Предполагаю, что при большем количестве эпох можно еще лучще получить f1 скор. Могу объяснить это улучшенной архитектурой LSTM с более умной памятью (использование гейтов и тд)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdd1a1-51f4-4065-85f7-22ed773a2628",
   "metadata": {},
   "source": [
    "__Задание 6 (2 балла).__ Главный недостаток RNN моделей заключается в том, что при сжатии всей информации в один вектор, важные детали пропадают. Для решения этой проблемы был придуман механизм внимания. Реализуйте его по [оригинальной статье](https://arxiv.org/abs/1409.0473). Замерьте качество и сделайте выводы.   \n",
    "Обратите внимание, что метод был предложен для Encoder-Decoder моделей. В нашем случае декодера нет, поэтому встройте внимание в энкодер: каждый блок LSTM будет смотреть на выходы всех предыдущих блоков.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd1fa9-2c1f-4268-be24-5c31752204ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "\n",
    "        self.W_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_s = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_a = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        self.W_c = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (B, T, E)\n",
    "        h_seq, (h_T, c_T) = self.lstm(embedded)  # h_seq: (B, T, H)\n",
    "\n",
    "\n",
    "        enhanced_h = []\n",
    "\n",
    "        for t in range(h_seq.size(1)):\n",
    "            h_t = h_seq[:, t, :]  # (B, H)\n",
    "\n",
    "            past_h = h_seq[:, :t+1, :]  # (B, t+1, H)\n",
    "\n",
    "\n",
    "            scores = self.v_a(torch.tanh(\n",
    "                self.W_h(past_h) + self.W_s(h_t).unsqueeze(1)\n",
    "            )).squeeze(-1)  # (B, t+1)\n",
    "\n",
    "\n",
    "            attn_weights = F.softmax(scores, dim=-1)  # (B, t+1)\n",
    "\n",
    "\n",
    "            c_t = torch.bmm(attn_weights.unsqueeze(1), past_h).squeeze(1)  # (B, H)\n",
    "\n",
    "            h_t_tilde = torch.tanh(self.W_c(torch.cat([h_t, c_t], dim=-1)))  # (B, H)\n",
    "            enhanced_h.append(h_t_tilde.unsqueeze(1))\n",
    "\n",
    "\n",
    "        enhanced_h = torch.cat(enhanced_h, dim=1)  # (B, T, H)\n",
    "\n",
    "\n",
    "        logits = self.fc(enhanced_h[:, -1, :])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0437ae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 0.2309 | test F1 0.0239\n",
      "epoch 02 | train loss 0.1815 | test F1 0.0000\n",
      "epoch 03 | train loss 0.1805 | test F1 0.0240\n",
      "epoch 04 | train loss 0.1810 | test F1 0.0240\n",
      "epoch 05 | train loss 0.1808 | test F1 0.0240\n",
      "epoch 06 | train loss 0.1815 | test F1 0.0240\n",
      "epoch 07 | train loss 0.1806 | test F1 0.0240\n",
      "epoch 08 | train loss 0.1806 | test F1 0.0000\n",
      "epoch 09 | train loss 0.1811 | test F1 0.0240\n",
      "epoch 10 | train loss 0.1802 | test F1 0.0099\n",
      "epoch 11 | train loss 0.1811 | test F1 0.0000\n",
      "epoch 12 | train loss 0.1806 | test F1 0.0240\n",
      "epoch 13 | train loss 0.1810 | test F1 0.0240\n",
      "epoch 14 | train loss 0.1814 | test F1 0.0240\n",
      "epoch 15 | train loss 0.1811 | test F1 0.0240\n",
      "epoch 16 | train loss 0.1809 | test F1 0.0338\n",
      "epoch 17 | train loss 0.1811 | test F1 0.0099\n",
      "epoch 18 | train loss 0.1808 | test F1 0.0240\n",
      "epoch 19 | train loss 0.1815 | test F1 0.0240\n",
      "epoch 20 | train loss 0.1806 | test F1 0.0240\n",
      "epoch 21 | train loss 0.1808 | test F1 0.0000\n",
      "epoch 22 | train loss 0.1808 | test F1 0.0239\n",
      "epoch 23 | train loss 0.1799 | test F1 0.0000\n",
      "epoch 24 | train loss 0.1800 | test F1 0.0240\n",
      "epoch 25 | train loss 0.1789 | test F1 0.0237\n",
      "epoch 26 | train loss 0.1709 | test F1 0.0349\n",
      "epoch 27 | train loss 0.1586 | test F1 0.0504\n",
      "epoch 28 | train loss 0.1484 | test F1 0.0498\n",
      "epoch 29 | train loss 0.1389 | test F1 0.0549\n",
      "epoch 30 | train loss 0.1285 | test F1 0.0723\n",
      "epoch 31 | train loss 0.1136 | test F1 0.0752\n",
      "epoch 32 | train loss 0.0994 | test F1 0.0903\n",
      "epoch 33 | train loss 0.0820 | test F1 0.1198\n",
      "epoch 34 | train loss 0.0631 | test F1 0.1795\n",
      "epoch 35 | train loss 0.0448 | test F1 0.2579\n",
      "epoch 36 | train loss 0.0308 | test F1 0.3008\n",
      "epoch 37 | train loss 0.0213 | test F1 0.3496\n",
      "epoch 38 | train loss 0.0151 | test F1 0.3954\n",
      "epoch 39 | train loss 0.0114 | test F1 0.3918\n",
      "epoch 40 | train loss 0.0092 | test F1 0.4099\n",
      "epoch 41 | train loss 0.0076 | test F1 0.4087\n",
      "epoch 42 | train loss 0.0066 | test F1 0.4055\n",
      "epoch 43 | train loss 0.0060 | test F1 0.4118\n",
      "epoch 44 | train loss 0.0053 | test F1 0.4124\n",
      "epoch 45 | train loss 0.0048 | test F1 0.4136\n",
      "epoch 46 | train loss 0.0045 | test F1 0.4119\n",
      "epoch 47 | train loss 0.0042 | test F1 0.4106\n",
      "epoch 48 | train loss 0.0039 | test F1 0.4137\n",
      "epoch 49 | train loss 0.0037 | test F1 0.4116\n",
      "epoch 50 | train loss 0.0036 | test F1 0.4119\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_labels = y_train.shape[1]\n",
    "\n",
    "model = AttentionLSTM(vocab_size, embedding_dim=256, hidden_dim=256,\n",
    "               output_dim=y_train.shape[1], pad_idx=PAD_ID).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).int().cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y.cpu().int())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    return compute_f1(y_true, y_pred)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    test_f1 = evaluate(model, test_loader)\n",
    "    f1_scores.append(test_f1)\n",
    "    print(f\"epoch {epoch:02d} | train loss {total_loss/len(train_loader):.4f} | test F1 {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "773d4909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6214685"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c810e583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4137022086923262"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8e075",
   "metadata": {},
   "source": [
    "Качество еще улучишлось :) СЮДАААА"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phQ-ka4mp0oS",
   "metadata": {
    "id": "phQ-ka4mp0oS"
   },
   "source": [
    "__Задание 7 (1 балл).__ Добавьте в вашу реализации возможность увеличивать число слоев LSTM. Обучите модель с двумя слоями и замерьте качество. Сделайте выводы: стоит ли увеличивать размер модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee7c7177",
   "metadata": {
    "id": "ee7c7177"
   },
   "outputs": [],
   "source": [
    "class StackedAttentionLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.W_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_s = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_a = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        self.W_c = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        h_seq, (h_n, c_n) = self.lstm(embedded)\n",
    "\n",
    "\n",
    "        enhanced_h = []\n",
    "        for t in range(h_seq.size(1)):\n",
    "            h_t = h_seq[:, t, :]\n",
    "            past_h = h_seq[:, :t+1, :]\n",
    "\n",
    "            scores = self.v_a(torch.tanh(\n",
    "                self.W_h(past_h) + self.W_s(h_t).unsqueeze(1)\n",
    "            )).squeeze(-1)\n",
    "\n",
    "            attn_weights = torch.softmax(scores, dim=-1)\n",
    "            c_t = torch.bmm(attn_weights.unsqueeze(1), past_h).squeeze(1)\n",
    "            h_t_tilde = torch.tanh(self.W_c(torch.cat([h_t, c_t], dim=-1)))\n",
    "            enhanced_h.append(h_t_tilde.unsqueeze(1))\n",
    "\n",
    "        enhanced_h = torch.cat(enhanced_h, dim=1)\n",
    "        logits = self.fc(enhanced_h[:, -1, :])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68509abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 0.3214 | test F1 0.0000\n",
      "epoch 02 | train loss 0.1811 | test F1 0.0230\n",
      "epoch 03 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 04 | train loss 0.1804 | test F1 0.0230\n",
      "epoch 05 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 06 | train loss 0.1802 | test F1 0.0230\n",
      "epoch 07 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 08 | train loss 0.1804 | test F1 0.0230\n",
      "epoch 09 | train loss 0.1804 | test F1 0.0230\n",
      "epoch 10 | train loss 0.1805 | test F1 0.0000\n",
      "epoch 11 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 12 | train loss 0.1806 | test F1 0.0000\n",
      "epoch 13 | train loss 0.1805 | test F1 0.0230\n",
      "epoch 14 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 15 | train loss 0.1807 | test F1 0.0230\n",
      "epoch 16 | train loss 0.1804 | test F1 0.0230\n",
      "epoch 17 | train loss 0.1805 | test F1 0.0230\n",
      "epoch 18 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 19 | train loss 0.1803 | test F1 0.0230\n",
      "epoch 20 | train loss 0.1803 | test F1 0.0197\n",
      "epoch 21 | train loss 0.1794 | test F1 0.0199\n",
      "epoch 22 | train loss 0.1757 | test F1 0.0219\n",
      "epoch 23 | train loss 0.1717 | test F1 0.0233\n",
      "epoch 24 | train loss 0.1668 | test F1 0.0239\n",
      "epoch 25 | train loss 0.1640 | test F1 0.0224\n",
      "epoch 26 | train loss 0.1605 | test F1 0.0237\n",
      "epoch 27 | train loss 0.1573 | test F1 0.0248\n",
      "epoch 28 | train loss 0.1546 | test F1 0.0251\n",
      "epoch 29 | train loss 0.1514 | test F1 0.0250\n",
      "epoch 30 | train loss 0.1489 | test F1 0.0345\n",
      "epoch 31 | train loss 0.1459 | test F1 0.0346\n",
      "epoch 32 | train loss 0.1426 | test F1 0.0351\n",
      "epoch 33 | train loss 0.1387 | test F1 0.0506\n",
      "epoch 34 | train loss 0.1344 | test F1 0.0538\n",
      "epoch 35 | train loss 0.1302 | test F1 0.0549\n",
      "epoch 36 | train loss 0.1264 | test F1 0.0552\n",
      "epoch 37 | train loss 0.1223 | test F1 0.0554\n",
      "epoch 38 | train loss 0.1182 | test F1 0.0578\n",
      "epoch 39 | train loss 0.1147 | test F1 0.0566\n",
      "epoch 40 | train loss 0.1114 | test F1 0.0614\n",
      "epoch 41 | train loss 0.1084 | test F1 0.0662\n",
      "epoch 42 | train loss 0.1041 | test F1 0.0632\n",
      "epoch 43 | train loss 0.1012 | test F1 0.0701\n",
      "epoch 44 | train loss 0.0973 | test F1 0.0804\n",
      "epoch 45 | train loss 0.0944 | test F1 0.0835\n",
      "epoch 46 | train loss 0.0913 | test F1 0.0885\n",
      "epoch 47 | train loss 0.0881 | test F1 0.0877\n",
      "epoch 48 | train loss 0.0856 | test F1 0.0905\n",
      "epoch 49 | train loss 0.0826 | test F1 0.0960\n",
      "epoch 50 | train loss 0.0796 | test F1 0.1125\n"
     ]
    }
   ],
   "source": [
    "model = StackedAttentionLSTM(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=100,\n",
    "    hidden_dim=64,\n",
    "    output_dim=y_train.shape[1],\n",
    "    pad_idx=PAD_ID,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_labels = y_train.shape[1]\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).int().cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y.cpu().int())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    return compute_f1(y_true, y_pred)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    test_f1 = evaluate(model, test_loader)\n",
    "    f1_scores.append(test_f1)\n",
    "    print(f\"epoch {epoch:02d} | train loss {total_loss/len(train_loader):.4f} | test F1 {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effc587",
   "metadata": {},
   "source": [
    "Качество ухудшилось :( Причем существенно - могу сделать вывод, что не следует делать увеличение количества слоев (иначе придется тюнить гиперпараметры, что возможно усложнит задачу) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbdf8b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "HSE_NLP (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12b0627d4aaf46c0adc64b442bf88d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d5b2e090c51406e953b4eec4b0b91ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "282f83858a424e2ea76990eb957dc5a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32808478ae8c4242beb79f0272ea6b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e8d1401c0e4dc1a8e71bbad7c2f74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b23f3b8b7247491c8d5e3ead7f54d886",
      "placeholder": "​",
      "style": "IPY_MODEL_cb632291897f4f9db86a00a5a71ca35f",
      "value": " 40/40 [36:41&lt;00:00, 51.61s/it]"
     }
    },
    "3735627f227d4b4f927955113111409f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f4f11bc6984b96ac3c3875d733f0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc4f687f9d5940aba074e2bb41581c93",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e10fd6d1a6c47a9ac34a47ae5ba708b",
      "value": 40
     }
    },
    "4aab16bb20824688aadbd23460adad9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f65eec1b45de42e59fb9e24b99aad917",
       "IPY_MODEL_47f4f11bc6984b96ac3c3875d733f0ba",
       "IPY_MODEL_f58fddb1bf414071b0523701a619ad71"
      ],
      "layout": "IPY_MODEL_32808478ae8c4242beb79f0272ea6b1f"
     }
    },
    "4de9492961d841aa9f3d7bc629911296": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67ae0c089c4a426db3b52976fae1a9dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e10fd6d1a6c47a9ac34a47ae5ba708b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b23f3b8b7247491c8d5e3ead7f54d886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc4165ff8fc3480fb1590b6ecd39fb4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cba16e32a9df4b1b89b4f7066945fc42",
       "IPY_MODEL_e8f0522f19c44066b5a78ded999f050a",
       "IPY_MODEL_34e8d1401c0e4dc1a8e71bbad7c2f74d"
      ],
      "layout": "IPY_MODEL_282f83858a424e2ea76990eb957dc5a0"
     }
    },
    "cb632291897f4f9db86a00a5a71ca35f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cba16e32a9df4b1b89b4f7066945fc42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67ae0c089c4a426db3b52976fae1a9dc",
      "placeholder": "​",
      "style": "IPY_MODEL_12b0627d4aaf46c0adc64b442bf88d0a",
      "value": "100%"
     }
    },
    "d7ed88f49793494bbdb3c2fffc01b216": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc4f687f9d5940aba074e2bb41581c93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7876fd73da349ea873c137c63d8d528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8f0522f19c44066b5a78ded999f050a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4de9492961d841aa9f3d7bc629911296",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7876fd73da349ea873c137c63d8d528",
      "value": 40
     }
    },
    "f58fddb1bf414071b0523701a619ad71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d5b2e090c51406e953b4eec4b0b91ad",
      "placeholder": "​",
      "style": "IPY_MODEL_3735627f227d4b4f927955113111409f",
      "value": " 40/40 [1:08:10&lt;00:00, 102.17s/it]"
     }
    },
    "f65eec1b45de42e59fb9e24b99aad917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f67dc08a01ac40ad98ed553fe6b7e948",
      "placeholder": "​",
      "style": "IPY_MODEL_d7ed88f49793494bbdb3c2fffc01b216",
      "value": "100%"
     }
    },
    "f67dc08a01ac40ad98ed553fe6b7e948": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
